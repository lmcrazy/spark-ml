#!/usr/bin/python
# -*- coding:utf-8 -*-
 
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import ElasticNetCV
import sklearn.datasets
from pprint import pprint
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
import warnings
 
 
def not_empty(s):
    return s != ''
 
 
if __name__ == "__main__":
    warnings.filterwarnings(action='ignore')                  #忽略警告信息
    np.set_printoptions(suppress=True)                        #设置打印选项，将输出以小数的形式呈现，默认为False，即以科学计数法
    file_data = pd.read_csv('.\\housing.data', header=None)    #header=None 表示原始数据中没有列索引
    # a = np.array([float(s) for s in str if s != ''])
    data = np.empty((len(file_data), 14))
    # print(file_data)                          #把数据读取出来
    # print(data)                               #形成一个以file_data 的长度为行，14为列的数组
    # print(file_data.shape)                     #506*1的数组
    # print(data.shape)                          #形成一个506*14的数组
    # print(file_data.values)
    # print(file_data.values.shape)                #打印出对应的值，506*1
 
    for i, d in enumerate(file_data.values):
 
        #filter()函数接收一个函数 f 和一个list，这个函数 f 的作用是对每个元素进行判断，返回 True或 False，filter()根据判断结果自动过滤掉不符合条件的元素，返回由符合条件元素组成的新list
  
        #首先过滤掉非空元素,然后将列表中的每个元素转换成float类型
 
        d = list(map(float, list(filter(not_empty, d[0].split(' ')))))
    # map()是 Python 内置的高阶函数，它接收一个函数 f 和一个 list，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 并返回
        data[i] = d
    x, y = np.split(data, (13, ), axis=1)          #指定进行列操作，将数据中13列进行分割，x是前13列数据，y是后面的数据
    # # data = sklearn.datasets.load_boston()
    # # x = np.array(data.data)
    # # y = np.array(data.target)
    print('样本个数：%d, 特征个数：%d' % x.shape)
    print(y.shape)
    y = y.ravel()
 
    #构建训练集和测试集
    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)
    """
    #Pipeline可以将许多算法模型串联起来，比如将特征提取、归一化、分类组织在一起形成一个典型的机器学习问题工作流。主要带来两点好处：  
    #1. 直接调用fit和predict方法来对pipeline中的所有算法模型进行训练和预测。  
    #2. 可以结合grid search对参数进行选择开始建模...
    """
    # model = Pipeline([
    #     ('ss', StandardScaler()),
    #     ('poly', PolynomialFeatures(degree=3, include_bias=True)),
    #     ('linear', ElasticNetCV(l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.99, 1], alphas=np.logspace(-3, 2, 5),
    #                             fit_intercept=False, max_iter=1e3, cv=3))
    # ])
    model = RandomForestRegressor(n_estimators=50, criterion='mse')
    print('开始建模...')
    model.fit(x_train, y_train)
    # linear = model.get_params('linear')['linear']
    # print u'超参数：', linear.alpha_
    # print u'L1 ratio：', linear.l1_ratio_
    # print u'系数：', linear.coef_.ravel()
    #
    order = y_test.argsort(axis=0)
    y_test = y_test[order]
    x_test = x_test[order, :]
    y_pred = model.predict(x_test)
    r2 = model.score(x_test, y_test)
    mse = mean_squared_error(y_test, y_pred)
    print('R2:', r2)
    print('均方误差：', mse)
    #
    t = np.arange(len(y_pred))
    mpl.rcParams['font.sans-serif'] = ['simHei']
    mpl.rcParams['axes.unicode_minus'] = False
    plt.figure(facecolor='w')
    plt.plot(t, y_test, 'r-', lw=2, label='真实值')
    plt.plot(t, y_pred, 'g-', lw=2, label='估计值')
    plt.legend(loc='best')                              #将标签放在最好的位置，当我改为loc='upper left'时，图形出现的结果是一致的。
    plt.title('波士顿房价预测', fontsize=18)
    plt.xlabel('样本编号', fontsize=15)
    plt.ylabel('房屋价格', fontsize=15)
    plt.grid()
    plt.show()
